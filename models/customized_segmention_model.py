from rs_foundation_model.models.dinov2_model import DINOV2PretrainedModel
import torch
import torch.nn as nn
from transformers.modeling_outputs import SemanticSegmenterOutput
import math
import warnings
from dinov2.models.vision_transformer import DinoVisionTransformer


def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1.0 + math.erf(x / math.sqrt(2.0))) / 2.0

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn(
            "mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
            "The distribution of values may be incorrect.",
            stacklevel=2,
        )

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.0))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0.0, std=1.0, a=-2.0, b=2.0):
    # type: (Tensor, float, float, float, float) -> Tensor
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)


class LinearClassifier(torch.nn.Module):
    def __init__(
        self,
        in_channels,
        tokenW=32,
        tokenH=32,
        num_class=1,
        use_projection=False,
        projection_dim_ratio=None,
    ):
        super(LinearClassifier, self).__init__()

        self.in_channels = in_channels
        self.width = tokenW
        self.height = tokenH
        self.use_projection = use_projection
        self.test = nn.Linear(in_channels, num_class)
        if self.use_projection:
            assert projection_dim_ratio, "please provide dimension reduce ratio"
            out_channels = in_channels * projection_dim_ratio
            # self.projection = nn.Sequential(
            #     nn.LayerNorm(),
            #     torch.nn.Conv2d(in_channels, out_channels, (1, 1)),
            #     nn.ReLU(),
            # )
        else:
            out_channels = in_channels
        self.classifier = torch.nn.Conv2d(out_channels, num_class, (1, 1))

    def forward(self, embeddings):
        embeddings = embeddings.reshape(-1, self.height, self.width, self.in_channels)
        embeddings = embeddings.permute(0, 3, 1, 2)
        if self.use_projection:
            embeddings = self.projection(embeddings)
        return self.classifier(embeddings)


class mimic_DINOHead(nn.Module):
    def __init__(
        self,
        in_dim,
        out_dim,
        tokenW=32,
        tokenH=32,
        use_bn=False,
        use_init=False,
        norm_last_layer=True,
        nlayers=3,
        hidden_dim=2048,
        bottleneck_dim=256,
    ):
        super().__init__()
        self.in_dim = in_dim
        self.width = tokenW
        self.height = tokenH
        self.hidden_dim = hidden_dim
        self.bottleneck_dim = bottleneck_dim
        # only in continued pretraining we freeze the last layer
        norm_last_layer = out_dim != 1
        nlayers = max(nlayers, 1)
        if nlayers == 1:
            self.projection = nn.Conv2d(in_dim, hidden_dim, 1)
        else:
            layers = [nn.Conv2d(in_dim, hidden_dim, 1)]
            if use_bn:
                layers.append(nn.BatchNorm2d(hidden_dim))
            layers.append(nn.GELU())
            for _ in range(nlayers - 2):
                layers.append(nn.Conv2d(hidden_dim, hidden_dim, 1))
                if use_bn:
                    layers.append(nn.BatchNorm2d(hidden_dim))
                layers.append(nn.GELU())
            layers.append(nn.Conv2d(hidden_dim, bottleneck_dim, 1))
            self.projection = nn.Sequential(*layers)
        if use_init:
            self.apply(self._init_weights)
        self.classifier = nn.utils.weight_norm(nn.Conv2d(bottleneck_dim, out_dim, 1))
        self.classifier.weight_g.data.fill_(1)
        if norm_last_layer:
            self.classifier.weight_g.requires_grad = False

    def _init_weights(self, m):
        if isinstance(m, nn.Conv2d):
            trunc_normal_(m.weight, std=0.02)
            if isinstance(m, nn.Conv2d) and m.bias is not None:
                nn.init.constant_(m.bias, 0)

    def forward(self, embeddings):
        embeddings = embeddings.reshape(-1, self.height, self.width, self.in_dim)
        embeddings = embeddings.permute(0, 3, 1, 2)
        embeddings = self.projection(embeddings)
        embeddings = nn.functional.normalize(embeddings, dim=-1, p=2)
        return self.classifier(embeddings)


class Dinov2ForSemanticSegmentation(nn.Module):
    def __init__(self, cfg, img_size=512, patch_size=16, save_cfg=True):
        super().__init__()
        self.config = cfg
        self.dinov2 = DINOV2PretrainedModel(cfg, save_cfg=save_cfg)
        self.num_class = len(cfg.MODEL_INFO.class_of_interest) + 1
        if isinstance(self.dinov2.model, DinoVisionTransformer):
            self.hidden_size = self.dinov2.model.patch_embed.proj.out_channels
        else:
            self.hidden_size = self.dinov2.model.embed_dim[0]
        self.patch_size = self.dinov2.config.student.patch_size
        self.num_register = self.dinov2.config.student.num_register_tokens
        self.height = self.width = img_size // patch_size
        self.feature_fusion = nn.Linear(self.hidden_size * 4, self.hidden_size)
        # self.classifier = LinearClassifier(
        #     self.hidden_size, self.width, self.height, num_class=self.num_class
        # )
        self.classifier = mimic_DINOHead(
            in_dim=self.hidden_size,
            out_dim=self.num_class,
            tokenW=self.width,
            tokenH=self.height,
            use_init=self.config.MODEL.architecture.use_init,
            use_bn=self.config.MODEL.architecture.use_bn,
            nlayers=self.config.MODEL.architecture.num_layers,
            hidden_dim=self.config.MODEL.architecture.hidden_dim,
            bottleneck_dim=self.config.MODEL.architecture.bottleneck_dim,
        )

    def forward(self, pixel_values, labels=None, doy=None):
        if isinstance(self.dinov2.model, DinoVisionTransformer):
            # will use the last four attention layers
            outputs = self.dinov2.model.get_intermediate_layers(
                pixel_values, 4, doy=doy
            )
            patch_embeddings = torch.concatenate(outputs, dim=2)
            # convert to logits and upsample to the size of the pixel values
            fused_embeddings = self.feature_fusion(patch_embeddings)
            logits = self.classifier(fused_embeddings)
            logits = torch.nn.functional.interpolate(
                logits,
                size=pixel_values.shape[2:],
                mode="bilinear",
                align_corners=False,
            )
        else:
            # only use the last layer
            outputs = self.dinov2.model(
                pixel_values[0], pixel_values[1], is_training=True, doy=doy
            )
            logits = self.classifier(outputs["x_norm_patchtokens"])
            logits = torch.nn.functional.interpolate(
                logits,
                size=pixel_values[0].shape[2:],
                mode="bilinear",
                align_corners=False,
            )

        loss = None
        if labels is not None:
            if self.config.MODEL_INFO.class_weight:
                loss_fct = torch.nn.CrossEntropyLoss(
                    weight=torch.tensor(
                        self.config.MODEL_INFO.class_weight, dtype=torch.float32
                    ).cuda(),
                )
            else:
                loss_fct = torch.nn.CrossEntropyLoss()
            if labels.dtype != torch.cuda.LongTensor:
                labels = labels.type(torch.cuda.LongTensor)
            logits = logits.squeeze() if self.num_class != 1 else logits
            loss = loss_fct(logits, labels)

        return SemanticSegmenterOutput(loss=loss, logits=logits)
